{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Buffett111/CEFR-SP/blob/main/ExtractiveSummarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBuLscPIy3-5"
      },
      "source": [
        "## Training the BERTSUM model\n",
        "The code for training a BERTSUM model is open-sourced by the researchers of BERTSUM and it is available at https://github.com/nlpyang/BertSum. In this section, let us explore this and learn how to train the BERTSUM model. We will train the BERTSUM model on the CNN/DailyMail news dataset.\n",
        "\n",
        "** Makse sure to run the notebook in GPU\n",
        "First, let us install the necessary libraries **\n",
        "\n",
        "## 1. Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnPpcH3LJTBl",
        "outputId": "b6a44695-fb92-4b51-84a4-1590a40a2eaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch_pretrained_bert\n",
            "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/123.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/123.8 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from pytorch_pretrained_bert) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch_pretrained_bert) (1.25.2)\n",
            "Collecting boto3 (from pytorch_pretrained_bert)\n",
            "  Downloading boto3-1.34.73-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pytorch_pretrained_bert) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch_pretrained_bert) (4.66.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from pytorch_pretrained_bert) (2023.12.25)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=0.4.1->pytorch_pretrained_bert)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=0.4.1->pytorch_pretrained_bert)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=0.4.1->pytorch_pretrained_bert)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=0.4.1->pytorch_pretrained_bert)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=0.4.1->pytorch_pretrained_bert)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=0.4.1->pytorch_pretrained_bert)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=0.4.1->pytorch_pretrained_bert)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=0.4.1->pytorch_pretrained_bert)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=0.4.1->pytorch_pretrained_bert)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=0.4.1->pytorch_pretrained_bert)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=0.4.1->pytorch_pretrained_bert)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=0.4.1->pytorch_pretrained_bert)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore<1.35.0,>=1.34.73 (from boto3->pytorch_pretrained_bert)\n",
            "  Downloading botocore-1.34.73-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->pytorch_pretrained_bert)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->pytorch_pretrained_bert)\n",
            "  Downloading s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch_pretrained_bert) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch_pretrained_bert) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch_pretrained_bert) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch_pretrained_bert) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.73->boto3->pytorch_pretrained_bert) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=0.4.1->pytorch_pretrained_bert) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=0.4.1->pytorch_pretrained_bert) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.73->boto3->pytorch_pretrained_bert) (1.16.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jmespath, nvidia-cusparse-cu12, nvidia-cudnn-cu12, botocore, s3transfer, nvidia-cusolver-cu12, boto3, pytorch_pretrained_bert\n",
            "Successfully installed boto3-1.34.73 botocore-1.34.73 jmespath-1.0.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 pytorch_pretrained_bert-0.6.2 s3transfer-0.10.1\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\n",
            "Collecting torch==1.11.0+cu113\n",
            "  Downloading https://download.pytorch.org/whl/cu113/torch-1.11.0%2Bcu113-cp310-cp310-linux_x86_64.whl (1637.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 GB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.12.0+cu113\n",
            "  Downloading https://download.pytorch.org/whl/cu113/torchvision-0.12.0%2Bcu113-cp310-cp310-linux_x86_64.whl (22.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.3/22.3 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==0.11.0\n",
            "  Downloading https://download.pytorch.org/whl/cu113/torchaudio-0.11.0%2Bcu113-cp310-cp310-linux_x86_64.whl (2.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.11.0+cu113) (4.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0+cu113) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0+cu113) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0+cu113) (9.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0+cu113) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0+cu113) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0+cu113) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0+cu113) (2024.2.2)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.2.1+cu121\n",
            "    Uninstalling torch-2.2.1+cu121:\n",
            "      Successfully uninstalled torch-2.2.1+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.17.1+cu121\n",
            "    Uninstalling torchvision-0.17.1+cu121:\n",
            "      Successfully uninstalled torchvision-0.17.1+cu121\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.2.1+cu121\n",
            "    Uninstalling torchaudio-2.2.1+cu121:\n",
            "      Successfully uninstalled torchaudio-2.2.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchdata 0.7.1 requires torch>=2, but you have torch 1.11.0+cu113 which is incompatible.\n",
            "torchtext 0.17.1 requires torch==2.2.1, but you have torch 1.11.0+cu113 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.11.0+cu113 torchaudio-0.11.0+cu113 torchvision-0.12.0+cu113\n",
            "Collecting pytorch_transformers==1.2.0\n",
            "  Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.4/176.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_transformers==1.2.0) (1.11.0+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch_transformers==1.2.0) (1.25.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from pytorch_transformers==1.2.0) (1.34.73)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pytorch_transformers==1.2.0) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch_transformers==1.2.0) (4.66.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from pytorch_transformers==1.2.0) (2023.12.25)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from pytorch_transformers==1.2.0) (0.1.99)\n",
            "Collecting sacremoses (from pytorch_transformers==1.2.0)\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch_transformers==1.2.0) (4.10.0)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.73 in /usr/local/lib/python3.10/dist-packages (from boto3->pytorch_transformers==1.2.0) (1.34.73)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3->pytorch_transformers==1.2.0) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3->pytorch_transformers==1.2.0) (0.10.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch_transformers==1.2.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch_transformers==1.2.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch_transformers==1.2.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch_transformers==1.2.0) (2024.2.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses->pytorch_transformers==1.2.0) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses->pytorch_transformers==1.2.0) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.73->boto3->pytorch_transformers==1.2.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.73->boto3->pytorch_transformers==1.2.0) (1.16.0)\n",
            "Installing collected packages: sacremoses, pytorch_transformers\n",
            "Successfully installed pytorch_transformers-1.2.0 sacremoses-0.1.1\n",
            "Collecting tensorboardX==1.9\n",
            "  Downloading tensorboardX-1.9-py2.py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.7/190.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX==1.9) (1.25.2)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorboardX==1.9) (3.20.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tensorboardX==1.9) (1.16.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-1.9\n",
            "Collecting multiprocess==0.70.9\n",
            "  Downloading multiprocess-0.70.9.tar.gz (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting dill>=0.3.1 (from multiprocess==0.70.9)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: multiprocess\n",
            "  Building wheel for multiprocess (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for multiprocess: filename=multiprocess-0.70.9-py3-none-any.whl size=70930 sha256=d1777075ab2c051facff2ecaac9a8d67b20616799b2f7bbdd9f69a94f4540adc\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/b9/ff/72cd56f34f0b3edde101afa3bf54c1ba85b771d51e7eaa7b03\n",
            "Successfully built multiprocess\n",
            "Installing collected packages: dill, multiprocess\n",
            "Successfully installed dill-0.3.8 multiprocess-0.70.9\n",
            "Collecting pyrouge\n",
            "  Downloading pyrouge-0.1.3.tar.gz (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.5/60.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pyrouge\n",
            "  Building wheel for pyrouge (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyrouge: filename=pyrouge-0.1.3-py3-none-any.whl size=191604 sha256=a90e3ead5448966476713a110db97e6bd42db7f0096aebfc5e8f280b7e74cd49\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/67/12/c5dd8ef8b4152bb8789eafd2a74a734e2dc7bb9eae02b768e7\n",
            "Successfully built pyrouge\n",
            "Installing collected packages: pyrouge\n",
            "Successfully installed pyrouge-0.1.3\n",
            "Collecting googleDriveFileDownloader\n",
            "  Downloading googleDriveFileDownloader-1.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from googleDriveFileDownloader) (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->googleDriveFileDownloader) (2.5)\n",
            "Installing collected packages: googleDriveFileDownloader\n",
            "Successfully installed googleDriveFileDownloader-1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch_pretrained_bert\n",
        "!pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0 --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "!pip install pytorch_transformers==1.2.0\n",
        "!pip install tensorboardX==1.9\n",
        "!pip install multiprocess==0.70.9\n",
        "!pip install pyrouge\n",
        "!pip install googleDriveFileDownloader"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ** An Issue with Pyrouge (1/3) **\n",
        "\n",
        "This [colab](https://colab.research.google.com/drive/1-vAnr3d3W8GtqSCn4MwjrdQrzN0uCXzx?usp=sharing#scrollTo=nJrExsDcIJiB) project has resolved the [problem](https://github.com/nlpyang/BertSum/issues/35) with Pyrouge. Essentially, it involves cloning the two Pyrouge repositories into separate folders and then directing to the Pyrouge-1.5.5 within the tools folder."
      ],
      "metadata": {
        "id": "ADcBjfbu9ZXH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNRRL3gv8-r8",
        "outputId": "538ce500-35fe-4bf2-d020-9ca0d311d45f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyrouge in /usr/local/lib/python3.10/dist-packages (0.1.3)\n",
            "Collecting https://github.com/bheinzerling/pyrouge/archive/master.zip\n",
            "  Using cached https://github.com/bheinzerling/pyrouge/archive/master.zip\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pyrouge in /usr/local/lib/python3.10/dist-packages (0.1.3)\n",
            "Name: pyrouge\n",
            "Version: 0.1.3\n",
            "Summary: A Python wrapper for the ROUGE summarization evaluation package.\n",
            "Home-page: https://github.com/noutenki/pyrouge\n",
            "Author: Benjamin Heinzerling, Anders Johannsen\n",
            "Author-email: benjamin.heinzerling@h-its.org\n",
            "License: LICENSE.txt\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: \n",
            "Required-by: \n",
            "fatal: destination path 'pyrouge' already exists and is not an empty directory.\n",
            "2024-03-29 05:05:38,215 [MainThread  ] [INFO ]  Set ROUGE home directory to /content/pyrouge/tools/ROUGE-1.5.5.\n"
          ]
        }
      ],
      "source": [
        "!pip install pyrouge --upgrade\n",
        "!pip install https://github.com/bheinzerling/pyrouge/archive/master.zip\n",
        "!pip install pyrouge\n",
        "!pip show pyrouge\n",
        "!git clone https://github.com/andersjo/pyrouge.git\n",
        "from pyrouge import Rouge155\n",
        "!pyrouge_set_rouge_path '/content/pyrouge/tools/ROUGE-1.5.5'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ** An Issue with Pyrouge (2/3) **\n",
        "\n",
        "A new issue has arisen with ROUGE-1.5.5 related to the XML Parser. A potential solution can be found at the following links:\n",
        "\n",
        "* [https://blog.csdn.net/qq_33220757/article/details/105692883](https://blog.csdn.net/qq_33220757/article/details/105692883)\n",
        "\n",
        "* [http://kavita-ganesan.com/rouge-howto/#.X0fJey1ePOQ](http://kavita-ganesan.com/rouge-howto/#.X0fJey1ePOQ)"
      ],
      "metadata": {
        "id": "34B_es9oJuGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install libxml-parser-perl"
      ],
      "metadata": {
        "id": "32le1hSOVyP1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d832cae-b913-40ba-f58c-b99f9063c504"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libauthen-sasl-perl libclone-perl libdata-dump-perl libencode-locale-perl\n",
            "  libfile-listing-perl libfont-afm-perl libhtml-form-perl libhtml-format-perl\n",
            "  libhtml-parser-perl libhtml-tagset-perl libhtml-tree-perl\n",
            "  libhttp-cookies-perl libhttp-daemon-perl libhttp-date-perl\n",
            "  libhttp-message-perl libhttp-negotiate-perl libio-html-perl\n",
            "  libio-socket-ssl-perl liblwp-mediatypes-perl liblwp-protocol-https-perl\n",
            "  libmailtools-perl libnet-http-perl libnet-smtp-ssl-perl libnet-ssleay-perl\n",
            "  libtry-tiny-perl liburi-perl libwww-perl libwww-robotrules-perl netbase\n",
            "  perl-openssl-defaults\n",
            "Suggested packages:\n",
            "  libdigest-hmac-perl libgssapi-perl libcrypt-ssleay-perl libsub-name-perl\n",
            "  libbusiness-isbn-perl libauthen-ntlm-perl\n",
            "The following NEW packages will be installed:\n",
            "  libauthen-sasl-perl libclone-perl libdata-dump-perl libencode-locale-perl\n",
            "  libfile-listing-perl libfont-afm-perl libhtml-form-perl libhtml-format-perl\n",
            "  libhtml-parser-perl libhtml-tagset-perl libhtml-tree-perl\n",
            "  libhttp-cookies-perl libhttp-daemon-perl libhttp-date-perl\n",
            "  libhttp-message-perl libhttp-negotiate-perl libio-html-perl\n",
            "  libio-socket-ssl-perl liblwp-mediatypes-perl liblwp-protocol-https-perl\n",
            "  libmailtools-perl libnet-http-perl libnet-smtp-ssl-perl libnet-ssleay-perl\n",
            "  libtry-tiny-perl liburi-perl libwww-perl libwww-robotrules-perl\n",
            "  libxml-parser-perl netbase perl-openssl-defaults\n",
            "0 upgraded, 31 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 1,783 kB of archives.\n",
            "After this operation, 5,562 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 netbase all 6.3 [12.9 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libclone-perl amd64 0.45-1build3 [11.0 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libdata-dump-perl all 1.25-1 [25.9 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libencode-locale-perl all 1.05-1.1 [11.8 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libhttp-date-perl all 6.05-1 [9,920 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfile-listing-perl all 6.14-1 [11.2 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfont-afm-perl all 1.20-3 [13.6 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libhtml-tagset-perl all 3.20-4 [12.5 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 liburi-perl all 5.10-1 [78.8 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libhtml-parser-perl amd64 3.76-1build2 [88.4 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libio-html-perl all 1.004-2 [15.4 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 liblwp-mediatypes-perl all 6.04-1 [19.5 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libhttp-message-perl all 6.36-1 [76.8 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 libhtml-form-perl all 6.07-1 [22.2 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy/main amd64 libhtml-tree-perl all 5.07-2 [200 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/main amd64 libhtml-format-perl all 2.12-1.1 [41.3 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 libhttp-cookies-perl all 6.10-1 [18.4 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libhttp-daemon-perl all 6.13-1ubuntu0.1 [22.9 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 libhttp-negotiate-perl all 6.01-1 [12.5 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 perl-openssl-defaults amd64 5build2 [7,542 B]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnet-ssleay-perl amd64 1.92-1build2 [327 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 libio-socket-ssl-perl all 2.074-2 [192 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnet-http-perl all 6.22-1 [23.2 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy/main amd64 libtry-tiny-perl all 0.31-1 [21.8 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwww-robotrules-perl all 6.02-1 [12.6 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwww-perl all 6.61-1 [141 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu jammy/main amd64 liblwp-protocol-https-perl all 6.10-1 [10.9 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnet-smtp-ssl-perl all 1.04-1 [5,948 B]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu jammy/main amd64 libmailtools-perl all 2.21-1 [80.7 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxml-parser-perl amd64 2.46-3build1 [212 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu jammy/main amd64 libauthen-sasl-perl all 2.1600-1.1 [43.1 kB]\n",
            "Fetched 1,783 kB in 4s (501 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 31.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package netbase.\n",
            "(Reading database ... 121753 files and directories currently installed.)\n",
            "Preparing to unpack .../00-netbase_6.3_all.deb ...\n",
            "Unpacking netbase (6.3) ...\n",
            "Selecting previously unselected package libclone-perl.\n",
            "Preparing to unpack .../01-libclone-perl_0.45-1build3_amd64.deb ...\n",
            "Unpacking libclone-perl (0.45-1build3) ...\n",
            "Selecting previously unselected package libdata-dump-perl.\n",
            "Preparing to unpack .../02-libdata-dump-perl_1.25-1_all.deb ...\n",
            "Unpacking libdata-dump-perl (1.25-1) ...\n",
            "Selecting previously unselected package libencode-locale-perl.\n",
            "Preparing to unpack .../03-libencode-locale-perl_1.05-1.1_all.deb ...\n",
            "Unpacking libencode-locale-perl (1.05-1.1) ...\n",
            "Selecting previously unselected package libhttp-date-perl.\n",
            "Preparing to unpack .../04-libhttp-date-perl_6.05-1_all.deb ...\n",
            "Unpacking libhttp-date-perl (6.05-1) ...\n",
            "Selecting previously unselected package libfile-listing-perl.\n",
            "Preparing to unpack .../05-libfile-listing-perl_6.14-1_all.deb ...\n",
            "Unpacking libfile-listing-perl (6.14-1) ...\n",
            "Selecting previously unselected package libfont-afm-perl.\n",
            "Preparing to unpack .../06-libfont-afm-perl_1.20-3_all.deb ...\n",
            "Unpacking libfont-afm-perl (1.20-3) ...\n",
            "Selecting previously unselected package libhtml-tagset-perl.\n",
            "Preparing to unpack .../07-libhtml-tagset-perl_3.20-4_all.deb ...\n",
            "Unpacking libhtml-tagset-perl (3.20-4) ...\n",
            "Selecting previously unselected package liburi-perl.\n",
            "Preparing to unpack .../08-liburi-perl_5.10-1_all.deb ...\n",
            "Unpacking liburi-perl (5.10-1) ...\n",
            "Selecting previously unselected package libhtml-parser-perl:amd64.\n",
            "Preparing to unpack .../09-libhtml-parser-perl_3.76-1build2_amd64.deb ...\n",
            "Unpacking libhtml-parser-perl:amd64 (3.76-1build2) ...\n",
            "Selecting previously unselected package libio-html-perl.\n",
            "Preparing to unpack .../10-libio-html-perl_1.004-2_all.deb ...\n",
            "Unpacking libio-html-perl (1.004-2) ...\n",
            "Selecting previously unselected package liblwp-mediatypes-perl.\n",
            "Preparing to unpack .../11-liblwp-mediatypes-perl_6.04-1_all.deb ...\n",
            "Unpacking liblwp-mediatypes-perl (6.04-1) ...\n",
            "Selecting previously unselected package libhttp-message-perl.\n",
            "Preparing to unpack .../12-libhttp-message-perl_6.36-1_all.deb ...\n",
            "Unpacking libhttp-message-perl (6.36-1) ...\n",
            "Selecting previously unselected package libhtml-form-perl.\n",
            "Preparing to unpack .../13-libhtml-form-perl_6.07-1_all.deb ...\n",
            "Unpacking libhtml-form-perl (6.07-1) ...\n",
            "Selecting previously unselected package libhtml-tree-perl.\n",
            "Preparing to unpack .../14-libhtml-tree-perl_5.07-2_all.deb ...\n",
            "Unpacking libhtml-tree-perl (5.07-2) ...\n",
            "Selecting previously unselected package libhtml-format-perl.\n",
            "Preparing to unpack .../15-libhtml-format-perl_2.12-1.1_all.deb ...\n",
            "Unpacking libhtml-format-perl (2.12-1.1) ...\n",
            "Selecting previously unselected package libhttp-cookies-perl.\n",
            "Preparing to unpack .../16-libhttp-cookies-perl_6.10-1_all.deb ...\n",
            "Unpacking libhttp-cookies-perl (6.10-1) ...\n",
            "Selecting previously unselected package libhttp-daemon-perl.\n",
            "Preparing to unpack .../17-libhttp-daemon-perl_6.13-1ubuntu0.1_all.deb ...\n",
            "Unpacking libhttp-daemon-perl (6.13-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libhttp-negotiate-perl.\n",
            "Preparing to unpack .../18-libhttp-negotiate-perl_6.01-1_all.deb ...\n",
            "Unpacking libhttp-negotiate-perl (6.01-1) ...\n",
            "Selecting previously unselected package perl-openssl-defaults:amd64.\n",
            "Preparing to unpack .../19-perl-openssl-defaults_5build2_amd64.deb ...\n",
            "Unpacking perl-openssl-defaults:amd64 (5build2) ...\n",
            "Selecting previously unselected package libnet-ssleay-perl:amd64.\n",
            "Preparing to unpack .../20-libnet-ssleay-perl_1.92-1build2_amd64.deb ...\n",
            "Unpacking libnet-ssleay-perl:amd64 (1.92-1build2) ...\n",
            "Selecting previously unselected package libio-socket-ssl-perl.\n",
            "Preparing to unpack .../21-libio-socket-ssl-perl_2.074-2_all.deb ...\n",
            "Unpacking libio-socket-ssl-perl (2.074-2) ...\n",
            "Selecting previously unselected package libnet-http-perl.\n",
            "Preparing to unpack .../22-libnet-http-perl_6.22-1_all.deb ...\n",
            "Unpacking libnet-http-perl (6.22-1) ...\n",
            "Selecting previously unselected package libtry-tiny-perl.\n",
            "Preparing to unpack .../23-libtry-tiny-perl_0.31-1_all.deb ...\n",
            "Unpacking libtry-tiny-perl (0.31-1) ...\n",
            "Selecting previously unselected package libwww-robotrules-perl.\n",
            "Preparing to unpack .../24-libwww-robotrules-perl_6.02-1_all.deb ...\n",
            "Unpacking libwww-robotrules-perl (6.02-1) ...\n",
            "Selecting previously unselected package libwww-perl.\n",
            "Preparing to unpack .../25-libwww-perl_6.61-1_all.deb ...\n",
            "Unpacking libwww-perl (6.61-1) ...\n",
            "Selecting previously unselected package liblwp-protocol-https-perl.\n",
            "Preparing to unpack .../26-liblwp-protocol-https-perl_6.10-1_all.deb ...\n",
            "Unpacking liblwp-protocol-https-perl (6.10-1) ...\n",
            "Selecting previously unselected package libnet-smtp-ssl-perl.\n",
            "Preparing to unpack .../27-libnet-smtp-ssl-perl_1.04-1_all.deb ...\n",
            "Unpacking libnet-smtp-ssl-perl (1.04-1) ...\n",
            "Selecting previously unselected package libmailtools-perl.\n",
            "Preparing to unpack .../28-libmailtools-perl_2.21-1_all.deb ...\n",
            "Unpacking libmailtools-perl (2.21-1) ...\n",
            "Selecting previously unselected package libxml-parser-perl:amd64.\n",
            "Preparing to unpack .../29-libxml-parser-perl_2.46-3build1_amd64.deb ...\n",
            "Unpacking libxml-parser-perl:amd64 (2.46-3build1) ...\n",
            "Selecting previously unselected package libauthen-sasl-perl.\n",
            "Preparing to unpack .../30-libauthen-sasl-perl_2.1600-1.1_all.deb ...\n",
            "Unpacking libauthen-sasl-perl (2.1600-1.1) ...\n",
            "Setting up libhttp-date-perl (6.05-1) ...\n",
            "Setting up libfile-listing-perl (6.14-1) ...\n",
            "Setting up libfont-afm-perl (1.20-3) ...\n",
            "Setting up libclone-perl (0.45-1build3) ...\n",
            "Setting up libhtml-tagset-perl (3.20-4) ...\n",
            "Setting up libauthen-sasl-perl (2.1600-1.1) ...\n",
            "Setting up liblwp-mediatypes-perl (6.04-1) ...\n",
            "Setting up libtry-tiny-perl (0.31-1) ...\n",
            "Setting up perl-openssl-defaults:amd64 (5build2) ...\n",
            "Setting up libencode-locale-perl (1.05-1.1) ...\n",
            "Setting up libdata-dump-perl (1.25-1) ...\n",
            "Setting up libio-html-perl (1.004-2) ...\n",
            "Setting up netbase (6.3) ...\n",
            "Setting up liburi-perl (5.10-1) ...\n",
            "Setting up libhttp-message-perl (6.36-1) ...\n",
            "Setting up libnet-ssleay-perl:amd64 (1.92-1build2) ...\n",
            "Setting up libhttp-negotiate-perl (6.01-1) ...\n",
            "Setting up libhttp-cookies-perl (6.10-1) ...\n",
            "Setting up libnet-http-perl (6.22-1) ...\n",
            "Setting up libwww-robotrules-perl (6.02-1) ...\n",
            "Setting up libhttp-daemon-perl (6.13-1ubuntu0.1) ...\n",
            "Setting up libhtml-parser-perl:amd64 (3.76-1build2) ...\n",
            "Setting up libio-socket-ssl-perl (2.074-2) ...\n",
            "Setting up libhtml-form-perl (6.07-1) ...\n",
            "Setting up libhtml-tree-perl (5.07-2) ...\n",
            "Setting up libhtml-format-perl (2.12-1.1) ...\n",
            "Setting up libnet-smtp-ssl-perl (1.04-1) ...\n",
            "Setting up libmailtools-perl (2.21-1) ...\n",
            "Setting up liblwp-protocol-https-perl (6.10-1) ...\n",
            "Setting up libwww-perl (6.61-1) ...\n",
            "Setting up libxml-parser-perl:amd64 (2.46-3build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ** An Issue with Pyrouge (3/3) **\n",
        "\n",
        "A new issue has been identified with WordNet-2.0.exc.db. The solution can be found at [https://github.com/tagucci/pythonrouge](https://github.com/tagucci/pythonrouge)"
      ],
      "metadata": {
        "id": "6tLHHJ7EJ_mj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "cd pyrouge/tools/ROUGE-1.5.5/data\n",
        "rm WordNet-2.0.exc.db # only if exist\n",
        "cd WordNet-2.0-Exceptions\n",
        "rm WordNet-2.0.exc.db # only if exist\n",
        "\n",
        "./buildExeptionDB.pl . exc WordNet-2.0.exc.db\n",
        "cd ../\n",
        "ln -s WordNet-2.0-Exceptions/WordNet-2.0.exc.db WordNet-2.0.exc.db"
      ],
      "metadata": {
        "id": "uxd735ihV2fP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f275e034-3cea-4e09-ca41-bbf44cd9c24a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: cd: pyrouge/tools/ROUGE-1.5.5/data: No such file or directory\n",
            "rm: cannot remove 'WordNet-2.0.exc.db': No such file or directory\n",
            "/bin/bash: line 3: cd: WordNet-2.0-Exceptions: No such file or directory\n",
            "rm: cannot remove 'WordNet-2.0.exc.db': No such file or directory\n",
            "/bin/bash: line 6: ./buildExeptionDB.pl: No such file or directory\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlPf3bwrzLsw"
      },
      "source": [
        "Switch to the content directory with the following code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnH56bClUGh1",
        "outputId": "1d337783-ac54-4503-a3c3-f09eec3088a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "cd /content/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sunb-Q9IzSSE"
      },
      "source": [
        "## 1. Clone the BERTSUM repository:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbKWc9olUeUc",
        "outputId": "0f69254a-9f2f-4dc5-9927-c8e04f66701a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'BertSum'...\n",
            "remote: Enumerating objects: 301, done.\u001b[K\n",
            "remote: Counting objects: 100% (293/293), done.\u001b[K\n",
            "remote: Compressing objects: 100% (124/124), done.\u001b[K\n",
            "remote: Total 301 (delta 165), reused 290 (delta 164), pack-reused 8\u001b[K\n",
            "Receiving objects: 100% (301/301), 15.05 MiB | 14.58 MiB/s, done.\n",
            "Resolving deltas: 100% (165/165), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/nlpyang/BertSum.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-mEorS-Gac0",
        "outputId": "bac7663d-101a-4d8e-e982-fc2816ed258d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 56\n",
            "drwxr-xr-x 2 root root  4096 Mar 29 05:06 urls\n",
            "drwxr-xr-x 5 root root  4096 Mar 29 05:06 src\n",
            "drwxr-xr-x 2 root root  4096 Mar 29 05:06 logs\n",
            "drwxr-xr-x 2 root root  4096 Mar 29 05:06 models\n",
            "drwxr-xr-x 2 root root  4096 Mar 29 05:06 raw_data\n",
            "drwxr-xr-x 2 root root  4096 Mar 29 05:06 results\n",
            "-rw-r--r-- 1 root root   313 Mar 29 05:06 bert_config_uncased_base.json\n",
            "drwxr-xr-x 2 root root  4096 Mar 29 05:06 bert_data\n",
            "drwxr-xr-x 2 root root  4096 Mar 29 05:06 json_data\n",
            "-rw-r--r-- 1 root root 11357 Mar 29 05:06 LICENSE\n",
            "-rw-r--r-- 1 root root  5248 Mar 29 05:06 README.md\n"
          ]
        }
      ],
      "source": [
        "!ls -lt BertSum/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iuv_7mVCzVJ4"
      },
      "source": [
        "Now switch to the bert_data directory:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pKWHaxOUluq",
        "outputId": "040ab889-d3f9-4399-9d11-fabab5df4775"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/BertSum/bert_data\n"
          ]
        }
      ],
      "source": [
        "cd /content/BertSum/bert_data/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSYT6FbQcSYG"
      },
      "source": [
        "## 2. Download the CNN/DailyMail Dataset\n",
        "\n",
        "The researchers have made the preprocessed CNN/DailyMail news dataset accessible. Therefore, our first step is to download it.\n",
        "\n",
        "Please download either the subset [bertsum_data.zip](https://drive.google.com/file/d/108C5QohdhM9T3oe1GypAberdOLqF12P0/view?usp=sharing) or the full dataset [bertsum_data.zip](https://drive.google.com/uc?id=1x0d61LP9UAN389YN00z0Pv-7jQgirVg6&export=download) and upload it to the directory /content/BertSum/bert_data/.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpmWD7jiUvd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c67375f-4877-4155-f1df-a5d8be53b249"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "223M\tbertsum_data.zip\n",
            "Archive:  bertsum_data.zip\n",
            "   creating: bertsum_data/\n",
            "  inflating: bertsum_data/cnndm.test.0.bert.pt  \n",
            "  inflating: bertsum_data/cnndm.test.1.bert.pt  \n",
            "  inflating: bertsum_data/cnndm.test.2.bert.pt  \n",
            "  inflating: bertsum_data/cnndm.test.3.bert.pt  \n",
            "  inflating: bertsum_data/cnndm.test.4.bert.pt  \n",
            "  inflating: bertsum_data/cnndm.test.5.bert.pt  \n",
            "  inflating: bertsum_data/cnndm.train.0.bert.pt  \n",
            "  inflating: bertsum_data/cnndm.train.1.bert.pt  \n",
            "  inflating: bertsum_data/cnndm.train.10.bert.pt  \n",
            "  inflating: bertsum_data/cnndm.train.11.bert.pt  \n",
            "  inflating: bertsum_data/cnndm.train.12.bert.pt  \n",
            "  inflating: bertsum_data/cnndm.train.13.bert.pt  \n",
            "  inflating: bertsum_data/cnndm.train.14.bert.pt  \n",
            "  inflating: bertsum_data/cnndm.train.15.bert.pt  \n",
            "  inflating: bertsum_data/cnndm.train.16.bert.pt  \n",
            "  inflating: bertsum_data/cnndm.train.17.bert.pt  \n",
            "  inflating: bertsum_data/cnndm.train.18.bert.pt  \n",
            "  inflating: bertsum_data/cnndm.train.19.bert.pt  \n",
            "  inflating: bertsum_data/cnndm.train.2.bert.pt  \n",
            "  inflating: bertsum_data/cnndm.train.20.bert.pt  \n",
            "  inflating: bertsum_data/cnndm.train.21.bert.pt  \n",
            "  inflating: bertsum_data/cnndm.train.22.bert.pt  \n",
            "  inflating: bertsum_data/cnndm.train.23.bert.pt  \n",
            "  inflating: bertsum_data/cnndm.train.24.bert.pt  \n",
            "  inflating: bertsum_data/cnndm.train.25.bert.pt  \n",
            "  inflating: bertsum_data/cnndm.train.26.bert.pt  \n",
            "  inflating: bertsum_data/cnndm.train.27.bert.pt  \n",
            "  inflating: bertsum_data/cnndm.train.28.bert.pt  \n",
            "  inflating: bertsum_data/cnndm.train.29.bert.pt  \n",
            "  inflating: bertsum_data/cnndm.train.3.bert.pt  \n",
            "  inflating: bertsum_data/cnndm.train.30.bert.pt  \n",
            "  inflating: bertsum_data/cnndm.train.4.bert.pt  \n",
            "  inflating: bertsum_data/cnndm.train.5.bert.pt  \n",
            "  inflating: bertsum_data/cnndm.train.6.bert.pt  \n",
            "  inflating: bertsum_data/cnndm.train.7.bert.pt  \n",
            "  inflating: bertsum_data/cnndm.train.8.bert.pt  \n",
            "  inflating: bertsum_data/cnndm.train.9.bert.pt  \n",
            "  inflating: bertsum_data/cnndm.valid.0.bert.pt  \n",
            "  inflating: bertsum_data/cnndm.valid.1.bert.pt  \n",
            "  inflating: bertsum_data/cnndm.valid.2.bert.pt  \n",
            "  inflating: bertsum_data/cnndm.valid.3.bert.pt  \n",
            "  inflating: bertsum_data/cnndm.valid.4.bert.pt  \n",
            "  inflating: bertsum_data/cnndm.valid.5.bert.pt  \n",
            "  inflating: bertsum_data/cnndm.valid.6.bert.pt  \n"
          ]
        }
      ],
      "source": [
        "#from googleDriveFileDownloader import googleDriveFileDownloader\n",
        "#gdrive = googleDriveFileDownloader()\n",
        "#gdrive.downloadFile(\"https://drive.google.com/uc?id=1x0d61LP9UAN389YN00z0Pv-7jQgirVg6&export=download\")\n",
        "!du -h bertsum_data.zip\n",
        "!unzip bertsum_data.zip\n",
        "!mv bertsum_data/* ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yoxiPEVU0n3",
        "outputId": "85a560c3-f810-4dcf-ed5b-98dc960c54ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/BertSum/src\n"
          ]
        }
      ],
      "source": [
        "cd /content/BertSum/src"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Co6vacRkkFC",
        "outputId": "effb2d2b-037d-482e-c6a4-ce1478613735"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Mar 29 05:32:59 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuR0luUNvbB4"
      },
      "source": [
        "## 3. Model Training\n",
        "\n",
        "Begin training the BERTSUM model. The code below includes the argument -encoder classifier, indicating that the BERTSUM model is being trained using a classifier.\n",
        "\n",
        "Please change lines 31 and 34 in /content/BertSum/src/models/data_loader.py. Replace `mask = 1 - (src == 0)` with `mask = ~(src == 0)` and replace `mask_cls = 1 - (clss == 0)` with `mask_cls = ~(clss == 0)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZAV7xBpU4uX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c4ecf18-d385-436d-8769-02b63b30b669"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-03-29 07:21:16,965 INFO] Device ID 0\n",
            "[2024-03-29 07:21:16,966 INFO] Device cuda\n",
            "[2024-03-29 07:21:17,360 INFO] loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at ../temp/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "[2024-03-29 07:21:17,361 INFO] extracting archive file ../temp/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpm4ry5g50\n",
            "[2024-03-29 07:21:21,882 INFO] Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "[2024-03-29 07:21:29,226 INFO] Summarizer(\n",
            "  (bert): Bert(\n",
            "    (model): BertModel(\n",
            "      (embeddings): BertEmbeddings(\n",
            "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "        (position_embeddings): Embedding(512, 768)\n",
            "        (token_type_embeddings): Embedding(2, 768)\n",
            "        (LayerNorm): BertLayerNorm()\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (encoder): BertEncoder(\n",
            "        (layer): ModuleList(\n",
            "          (0): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (2): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (3): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (4): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (5): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (6): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (7): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (8): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (9): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (10): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (11): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): BertPooler(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (encoder): Classifier(\n",
            "    (linear1): Linear(in_features=768, out_features=1, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "  )\n",
            ")\n",
            "gpu_rank 0\n",
            "[2024-03-29 07:21:29,311 INFO] * number of parameters: 109483009\n",
            "[2024-03-29 07:21:29,311 INFO] Start training...\n",
            "[2024-03-29 07:21:29,399 INFO] Loading train dataset from ../bert_data/cnndm.train.4.bert.pt, number of examples: 2001\n",
            "[2024-03-29 07:23:31,773 INFO] Step 50/ 2000; xent: 4.85; lr: 0.0000032;  18 docs/s;    122 sec\n",
            "[2024-03-29 07:25:10,153 INFO] Loading train dataset from ../bert_data/cnndm.train.16.bert.pt, number of examples: 2001\n",
            "[2024-03-29 07:25:32,219 INFO] Step 100/ 2000; xent: 3.29; lr: 0.0000063;  18 docs/s;    243 sec\n",
            "[2024-03-29 07:27:33,396 INFO] Step 150/ 2000; xent: 3.28; lr: 0.0000095;  18 docs/s;    364 sec\n",
            "[2024-03-29 07:28:52,187 INFO] Loading train dataset from ../bert_data/cnndm.train.19.bert.pt, number of examples: 2000\n",
            "[2024-03-29 07:29:35,894 INFO] Step 200/ 2000; xent: 3.24; lr: 0.0000126;  18 docs/s;    486 sec\n",
            "[2024-03-29 07:31:36,678 INFO] Step 250/ 2000; xent: 3.30; lr: 0.0000158;  18 docs/s;    607 sec\n",
            "[2024-03-29 07:32:32,426 INFO] Loading train dataset from ../bert_data/cnndm.train.27.bert.pt, number of examples: 2001\n",
            "[2024-03-29 07:33:38,568 INFO] Step 300/ 2000; xent: 3.14; lr: 0.0000190;  18 docs/s;    729 sec\n",
            "[2024-03-29 07:35:39,832 INFO] Step 350/ 2000; xent: 3.13; lr: 0.0000221;  18 docs/s;    850 sec\n",
            "[2024-03-29 07:36:16,044 INFO] Loading train dataset from ../bert_data/cnndm.train.14.bert.pt, number of examples: 1998\n",
            "[2024-03-29 07:37:41,500 INFO] Step 400/ 2000; xent: 3.02; lr: 0.0000253;  18 docs/s;    972 sec\n",
            "[2024-03-29 07:39:43,319 INFO] Step 450/ 2000; xent: 2.99; lr: 0.0000285;  18 docs/s;   1094 sec\n",
            "[2024-03-29 07:39:55,912 INFO] Loading train dataset from ../bert_data/cnndm.train.22.bert.pt, number of examples: 1999\n",
            "[2024-03-29 07:41:45,594 INFO] Step 500/ 2000; xent: 3.02; lr: 0.0000316;  18 docs/s;   1216 sec\n",
            "[2024-03-29 07:41:45,596 INFO] Saving checkpoint ../models/bert_classifier/model_step_500.pt\n",
            "[2024-03-29 07:43:36,984 INFO] Loading train dataset from ../bert_data/cnndm.train.13.bert.pt, number of examples: 2001\n",
            "[2024-03-29 07:43:46,803 INFO] Step 550/ 2000; xent: 2.94; lr: 0.0000348;  18 docs/s;   1337 sec\n",
            "[2024-03-29 07:45:47,198 INFO] Step 600/ 2000; xent: 3.02; lr: 0.0000379;  18 docs/s;   1458 sec\n",
            "[2024-03-29 07:47:19,485 INFO] Loading train dataset from ../bert_data/cnndm.train.28.bert.pt, number of examples: 2000\n",
            "[2024-03-29 07:47:48,581 INFO] Step 650/ 2000; xent: 2.93; lr: 0.0000411;  18 docs/s;   1579 sec\n",
            "[2024-03-29 07:49:51,395 INFO] Step 700/ 2000; xent: 2.94; lr: 0.0000443;  18 docs/s;   1702 sec\n",
            "[2024-03-29 07:51:01,601 INFO] Loading train dataset from ../bert_data/cnndm.train.5.bert.pt, number of examples: 2001\n",
            "[2024-03-29 07:51:53,384 INFO] Step 750/ 2000; xent: 2.89; lr: 0.0000474;  18 docs/s;   1824 sec\n",
            "[2024-03-29 07:53:55,088 INFO] Step 800/ 2000; xent: 2.97; lr: 0.0000506;  18 docs/s;   1946 sec\n",
            "[2024-03-29 07:54:43,224 INFO] Loading train dataset from ../bert_data/cnndm.train.10.bert.pt, number of examples: 2001\n",
            "[2024-03-29 07:55:56,647 INFO] Step 850/ 2000; xent: 2.90; lr: 0.0000538;  18 docs/s;   2067 sec\n",
            "[2024-03-29 07:57:59,282 INFO] Step 900/ 2000; xent: 2.92; lr: 0.0000569;  18 docs/s;   2190 sec\n",
            "[2024-03-29 07:58:26,296 INFO] Loading train dataset from ../bert_data/cnndm.train.29.bert.pt, number of examples: 1999\n",
            "[2024-03-29 08:00:01,608 INFO] Step 950/ 2000; xent: 2.89; lr: 0.0000601;  18 docs/s;   2312 sec\n",
            "[2024-03-29 08:02:02,164 INFO] Step 1000/ 2000; xent: 2.86; lr: 0.0000632;  18 docs/s;   2433 sec\n",
            "[2024-03-29 08:02:02,167 INFO] Saving checkpoint ../models/bert_classifier/model_step_1000.pt\n",
            "[2024-03-29 08:02:07,305 INFO] Loading train dataset from ../bert_data/cnndm.train.6.bert.pt, number of examples: 2001\n",
            "[2024-03-29 08:04:04,535 INFO] Step 1050/ 2000; xent: 2.88; lr: 0.0000617;  18 docs/s;   2555 sec\n",
            "[2024-03-29 08:05:49,053 INFO] Loading train dataset from ../bert_data/cnndm.train.25.bert.pt, number of examples: 2001\n",
            "[2024-03-29 08:06:06,279 INFO] Step 1100/ 2000; xent: 2.89; lr: 0.0000603;  18 docs/s;   2677 sec\n",
            "[2024-03-29 08:08:07,080 INFO] Step 1150/ 2000; xent: 2.86; lr: 0.0000590;  18 docs/s;   2798 sec\n",
            "[2024-03-29 08:09:32,170 INFO] Loading train dataset from ../bert_data/cnndm.train.26.bert.pt, number of examples: 2000\n",
            "[2024-03-29 08:10:08,949 INFO] Step 1200/ 2000; xent: 2.84; lr: 0.0000577;  18 docs/s;   2920 sec\n",
            "[2024-03-29 08:12:11,514 INFO] Step 1250/ 2000; xent: 2.90; lr: 0.0000566;  18 docs/s;   3042 sec\n",
            "[2024-03-29 08:13:14,206 INFO] Loading train dataset from ../bert_data/cnndm.train.30.bert.pt, number of examples: 1997\n",
            "[2024-03-29 08:14:12,243 INFO] Step 1300/ 2000; xent: 2.86; lr: 0.0000555;  18 docs/s;   3163 sec\n",
            "[2024-03-29 08:16:14,747 INFO] Step 1350/ 2000; xent: 2.84; lr: 0.0000544;  18 docs/s;   3285 sec\n",
            "[2024-03-29 08:16:56,589 INFO] Loading train dataset from ../bert_data/cnndm.train.15.bert.pt, number of examples: 1999\n",
            "[2024-03-29 08:18:17,288 INFO] Step 1400/ 2000; xent: 2.83; lr: 0.0000535;  18 docs/s;   3408 sec\n",
            "[2024-03-29 08:20:19,039 INFO] Step 1450/ 2000; xent: 2.81; lr: 0.0000525;  18 docs/s;   3530 sec\n",
            "[2024-03-29 08:20:38,911 INFO] Loading train dataset from ../bert_data/cnndm.train.9.bert.pt, number of examples: 1999\n",
            "[2024-03-29 08:22:20,718 INFO] Step 1500/ 2000; xent: 2.89; lr: 0.0000516;  18 docs/s;   3651 sec\n",
            "[2024-03-29 08:22:20,721 INFO] Saving checkpoint ../models/bert_classifier/model_step_1500.pt\n",
            "[2024-03-29 08:24:20,894 INFO] Loading train dataset from ../bert_data/cnndm.train.8.bert.pt, number of examples: 2000\n",
            "[2024-03-29 08:24:23,361 INFO] Step 1550/ 2000; xent: 2.85; lr: 0.0000508;  18 docs/s;   3774 sec\n",
            "[2024-03-29 08:26:25,566 INFO] Step 1600/ 2000; xent: 2.79; lr: 0.0000500;  18 docs/s;   3896 sec\n",
            "[2024-03-29 08:28:01,921 INFO] Loading train dataset from ../bert_data/cnndm.train.12.bert.pt, number of examples: 2001\n",
            "[2024-03-29 08:28:26,541 INFO] Step 1650/ 2000; xent: 2.89; lr: 0.0000492;  18 docs/s;   4017 sec\n",
            "[2024-03-29 08:30:28,993 INFO] Step 1700/ 2000; xent: 2.85; lr: 0.0000485;  18 docs/s;   4140 sec\n",
            "[2024-03-29 08:31:44,128 INFO] Loading train dataset from ../bert_data/cnndm.train.1.bert.pt, number of examples: 2001\n",
            "[2024-03-29 08:32:29,708 INFO] Step 1750/ 2000; xent: 2.87; lr: 0.0000478;  18 docs/s;   4260 sec\n",
            "[2024-03-29 08:34:31,584 INFO] Step 1800/ 2000; xent: 2.85; lr: 0.0000471;  18 docs/s;   4382 sec\n",
            "[2024-03-29 08:35:25,815 INFO] Loading train dataset from ../bert_data/cnndm.train.11.bert.pt, number of examples: 1999\n",
            "[2024-03-29 08:36:33,164 INFO] Step 1850/ 2000; xent: 2.85; lr: 0.0000465;  18 docs/s;   4504 sec\n",
            "[2024-03-29 08:38:36,013 INFO] Step 1900/ 2000; xent: 2.86; lr: 0.0000459;  18 docs/s;   4627 sec\n",
            "[2024-03-29 08:39:06,976 INFO] Loading train dataset from ../bert_data/cnndm.train.18.bert.pt, number of examples: 1998\n",
            "[2024-03-29 08:40:36,541 INFO] Step 1950/ 2000; xent: 2.80; lr: 0.0000453;  18 docs/s;   4747 sec\n",
            "[2024-03-29 08:42:39,238 INFO] Step 2000/ 2000; xent: 2.81; lr: 0.0000447;  18 docs/s;   4870 sec\n",
            "[2024-03-29 08:42:39,240 INFO] Saving checkpoint ../models/bert_classifier/model_step_2000.pt\n",
            "[2024-03-29 08:42:39,329 INFO] Loading train dataset from ../bert_data/cnndm.train.16.bert.pt, number of examples: 2001\n"
          ]
        }
      ],
      "source": [
        "!python train.py -mode train -encoder classifier \\\n",
        "          -dropout 0.1 -bert_data_path ../bert_data/cnndm \\\n",
        "          -model_path ../models/bert_classifier -lr 2e-3 \\\n",
        "          -visible_gpus 0 -gpu_ranks 0 \\\n",
        "          -world_size 1 -report_every 50 \\\n",
        "          -save_checkpoint_steps 500 \\\n",
        "          -batch_size 6000 -decay_method noam \\\n",
        "          -train_steps 2000 -accum_count 2 \\\n",
        "          -log_file ../logs/bert_classifier \\\n",
        "          -use_interval true -warmup_steps 1000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYMzsKu30Lto"
      },
      "source": [
        "## 4. Model Evaluation\n",
        "\n",
        "* `-mode` can be {validate, test}, where validate will inspect the model directory and evaluate the model for each newly saved checkpoint, test need to be used with `-test_from`, indicating the checkpoint you want to use.\n",
        "* `-model_path` is the directory of saved checkpoints.\n",
        "* use `-mode` valiadte with `-test_all`, the system will load all saved checkpoints and select the top ones to generate summaries (this will take a while)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKz9LNhcvSVu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9918d7b9-cc5e-47fa-b742-56f9926153d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-03-29 09:07:26,961 INFO] Loading checkpoint from ../models/bert_classifier/model_step_500.pt\n",
            "Namespace(encoder='classifier', mode='validate', bert_data_path='../bert_data/cnndm', model_path='../models/bert_classifier', result_path='../models/bert_classifier/results', temp_dir='../temp', bert_config_path='../bert_config_uncased_base.json', batch_size=10000, use_interval=True, hidden_size=128, ff_size=512, heads=4, inter_layers=2, rnn_size=512, param_init=0, param_init_glorot=True, dropout=0.1, optim='adam', lr=1, beta1=0.9, beta2=0.999, decay_method='', warmup_steps=8000, max_grad_norm=0, save_checkpoint_steps=5, accum_count=1, world_size=1, report_every=1, train_steps=1000, recall_eval=False, visible_gpus='0', gpu_ranks=[0], log_file='../models/bert_classifier/log', dataset='', seed=666, test_all=True, test_from='', train_from='', report_rouge=True, block_trigram=True)\n",
            "[2024-03-29 09:07:40,875 INFO] Loading valid dataset from ../bert_data/cnndm.valid.0.bert.pt, number of examples: 2001\n",
            "gpu_rank 0\n",
            "[2024-03-29 09:07:40,877 INFO] * number of parameters: 109483009\n",
            "[2024-03-29 09:08:48,148 INFO] Loading valid dataset from ../bert_data/cnndm.valid.1.bert.pt, number of examples: 2001\n",
            "[2024-03-29 09:09:57,829 INFO] Loading valid dataset from ../bert_data/cnndm.valid.2.bert.pt, number of examples: 2001\n",
            "[2024-03-29 09:11:09,433 INFO] Loading valid dataset from ../bert_data/cnndm.valid.3.bert.pt, number of examples: 2000\n",
            "[2024-03-29 09:12:22,091 INFO] Loading valid dataset from ../bert_data/cnndm.valid.4.bert.pt, number of examples: 2001\n",
            "[2024-03-29 09:13:35,275 INFO] Loading valid dataset from ../bert_data/cnndm.valid.5.bert.pt, number of examples: 2001\n",
            "[2024-03-29 09:14:48,665 INFO] Loading valid dataset from ../bert_data/cnndm.valid.6.bert.pt, number of examples: 1362\n",
            "[2024-03-29 09:15:38,527 INFO] Validation xent: 5.98646 at step 500\n",
            "[2024-03-29 09:15:38,686 INFO] Loading checkpoint from ../models/bert_classifier/model_step_1000.pt\n",
            "Namespace(encoder='classifier', mode='validate', bert_data_path='../bert_data/cnndm', model_path='../models/bert_classifier', result_path='../models/bert_classifier/results', temp_dir='../temp', bert_config_path='../bert_config_uncased_base.json', batch_size=10000, use_interval=True, hidden_size=128, ff_size=512, heads=4, inter_layers=2, rnn_size=512, param_init=0, param_init_glorot=True, dropout=0.1, optim='adam', lr=1, beta1=0.9, beta2=0.999, decay_method='', warmup_steps=8000, max_grad_norm=0, save_checkpoint_steps=5, accum_count=1, world_size=1, report_every=1, train_steps=1000, recall_eval=False, visible_gpus='0', gpu_ranks=[0], log_file='../models/bert_classifier/log', dataset='', seed=666, test_all=True, test_from='', train_from='', report_rouge=True, block_trigram=True)\n",
            "[2024-03-29 09:15:47,400 INFO] Loading valid dataset from ../bert_data/cnndm.valid.0.bert.pt, number of examples: 2001\n",
            "gpu_rank 0\n",
            "[2024-03-29 09:15:47,413 INFO] * number of parameters: 109483009\n",
            "[2024-03-29 09:17:01,467 INFO] Loading valid dataset from ../bert_data/cnndm.valid.1.bert.pt, number of examples: 2001\n",
            "[2024-03-29 09:18:14,807 INFO] Loading valid dataset from ../bert_data/cnndm.valid.2.bert.pt, number of examples: 2001\n",
            "[2024-03-29 09:19:28,383 INFO] Loading valid dataset from ../bert_data/cnndm.valid.3.bert.pt, number of examples: 2000\n",
            "[2024-03-29 09:20:42,294 INFO] Loading valid dataset from ../bert_data/cnndm.valid.4.bert.pt, number of examples: 2001\n",
            "[2024-03-29 09:21:55,581 INFO] Loading valid dataset from ../bert_data/cnndm.valid.5.bert.pt, number of examples: 2001\n",
            "[2024-03-29 09:23:08,851 INFO] Loading valid dataset from ../bert_data/cnndm.valid.6.bert.pt, number of examples: 1362\n",
            "[2024-03-29 09:23:58,768 INFO] Validation xent: 5.81401 at step 1000\n",
            "[2024-03-29 09:23:58,795 INFO] Loading checkpoint from ../models/bert_classifier/model_step_1500.pt\n",
            "Namespace(encoder='classifier', mode='validate', bert_data_path='../bert_data/cnndm', model_path='../models/bert_classifier', result_path='../models/bert_classifier/results', temp_dir='../temp', bert_config_path='../bert_config_uncased_base.json', batch_size=10000, use_interval=True, hidden_size=128, ff_size=512, heads=4, inter_layers=2, rnn_size=512, param_init=0, param_init_glorot=True, dropout=0.1, optim='adam', lr=1, beta1=0.9, beta2=0.999, decay_method='', warmup_steps=8000, max_grad_norm=0, save_checkpoint_steps=5, accum_count=1, world_size=1, report_every=1, train_steps=1000, recall_eval=False, visible_gpus='0', gpu_ranks=[0], log_file='../models/bert_classifier/log', dataset='', seed=666, test_all=True, test_from='', train_from='', report_rouge=True, block_trigram=True)\n",
            "[2024-03-29 09:24:07,072 INFO] Loading valid dataset from ../bert_data/cnndm.valid.0.bert.pt, number of examples: 2001\n",
            "gpu_rank 0\n",
            "[2024-03-29 09:24:07,074 INFO] * number of parameters: 109483009\n",
            "[2024-03-29 09:25:21,137 INFO] Loading valid dataset from ../bert_data/cnndm.valid.1.bert.pt, number of examples: 2001\n",
            "[2024-03-29 09:26:34,731 INFO] Loading valid dataset from ../bert_data/cnndm.valid.2.bert.pt, number of examples: 2001\n",
            "[2024-03-29 09:27:48,361 INFO] Loading valid dataset from ../bert_data/cnndm.valid.3.bert.pt, number of examples: 2000\n",
            "[2024-03-29 09:29:02,167 INFO] Loading valid dataset from ../bert_data/cnndm.valid.4.bert.pt, number of examples: 2001\n",
            "[2024-03-29 09:30:15,517 INFO] Loading valid dataset from ../bert_data/cnndm.valid.5.bert.pt, number of examples: 2001\n",
            "[2024-03-29 09:31:29,061 INFO] Loading valid dataset from ../bert_data/cnndm.valid.6.bert.pt, number of examples: 1362\n",
            "[2024-03-29 09:32:19,133 INFO] Validation xent: 5.67124 at step 1500\n",
            "[2024-03-29 09:32:19,192 INFO] Loading checkpoint from ../models/bert_classifier/model_step_2000.pt\n",
            "Namespace(encoder='classifier', mode='validate', bert_data_path='../bert_data/cnndm', model_path='../models/bert_classifier', result_path='../models/bert_classifier/results', temp_dir='../temp', bert_config_path='../bert_config_uncased_base.json', batch_size=10000, use_interval=True, hidden_size=128, ff_size=512, heads=4, inter_layers=2, rnn_size=512, param_init=0, param_init_glorot=True, dropout=0.1, optim='adam', lr=1, beta1=0.9, beta2=0.999, decay_method='', warmup_steps=8000, max_grad_norm=0, save_checkpoint_steps=5, accum_count=1, world_size=1, report_every=1, train_steps=1000, recall_eval=False, visible_gpus='0', gpu_ranks=[0], log_file='../models/bert_classifier/log', dataset='', seed=666, test_all=True, test_from='', train_from='', report_rouge=True, block_trigram=True)\n",
            "[2024-03-29 09:32:28,198 INFO] Loading valid dataset from ../bert_data/cnndm.valid.0.bert.pt, number of examples: 2001\n",
            "gpu_rank 0\n",
            "[2024-03-29 09:32:28,202 INFO] * number of parameters: 109483009\n",
            "[2024-03-29 09:33:42,359 INFO] Loading valid dataset from ../bert_data/cnndm.valid.1.bert.pt, number of examples: 2001\n",
            "[2024-03-29 09:34:55,748 INFO] Loading valid dataset from ../bert_data/cnndm.valid.2.bert.pt, number of examples: 2001\n",
            "[2024-03-29 09:36:09,208 INFO] Loading valid dataset from ../bert_data/cnndm.valid.3.bert.pt, number of examples: 2000\n",
            "[2024-03-29 09:37:22,901 INFO] Loading valid dataset from ../bert_data/cnndm.valid.4.bert.pt, number of examples: 2001\n",
            "[2024-03-29 09:38:36,166 INFO] Loading valid dataset from ../bert_data/cnndm.valid.5.bert.pt, number of examples: 2001\n",
            "[2024-03-29 09:39:49,666 INFO] Loading valid dataset from ../bert_data/cnndm.valid.6.bert.pt, number of examples: 1362\n",
            "[2024-03-29 09:40:39,806 INFO] Validation xent: 5.62764 at step 2000\n",
            "[2024-03-29 09:40:39,841 INFO] PPL [(5.6276377034702785, '../models/bert_classifier/model_step_2000.pt'), (5.67124462002831, '../models/bert_classifier/model_step_1500.pt'), (5.814006397466773, '../models/bert_classifier/model_step_1000.pt')]\n",
            "[2024-03-29 09:40:39,842 INFO] Loading checkpoint from ../models/bert_classifier/model_step_2000.pt\n",
            "Namespace(encoder='classifier', mode='validate', bert_data_path='../bert_data/cnndm', model_path='../models/bert_classifier', result_path='../models/bert_classifier/results', temp_dir='../temp', bert_config_path='../bert_config_uncased_base.json', batch_size=10000, use_interval=True, hidden_size=128, ff_size=512, heads=4, inter_layers=2, rnn_size=512, param_init=0, param_init_glorot=True, dropout=0.1, optim='adam', lr=1, beta1=0.9, beta2=0.999, decay_method='', warmup_steps=8000, max_grad_norm=0, save_checkpoint_steps=5, accum_count=1, world_size=1, report_every=1, train_steps=1000, recall_eval=False, visible_gpus='0', gpu_ranks=[0], log_file='../models/bert_classifier/log', dataset='', seed=666, test_all=True, test_from='', train_from='', report_rouge=True, block_trigram=True)\n",
            "[2024-03-29 09:40:42,018 INFO] Loading test dataset from ../bert_data/cnndm.test.0.bert.pt, number of examples: 2001\n",
            "gpu_rank 0\n",
            "[2024-03-29 09:40:42,020 INFO] * number of parameters: 109483009\n",
            "[2024-03-29 09:41:55,514 INFO] Loading test dataset from ../bert_data/cnndm.test.1.bert.pt, number of examples: 2001\n",
            "[2024-03-29 09:43:08,954 INFO] Loading test dataset from ../bert_data/cnndm.test.2.bert.pt, number of examples: 2001\n",
            "[2024-03-29 09:44:22,714 INFO] Loading test dataset from ../bert_data/cnndm.test.3.bert.pt, number of examples: 2001\n",
            "[2024-03-29 09:45:36,407 INFO] Loading test dataset from ../bert_data/cnndm.test.4.bert.pt, number of examples: 2000\n",
            "[2024-03-29 09:46:49,794 INFO] Loading test dataset from ../bert_data/cnndm.test.5.bert.pt, number of examples: 1485\n",
            "11489\n",
            "11489\n",
            "2024-03-29 09:47:45,622 [MainThread  ] [INFO ]  Writing summaries.\n",
            "[2024-03-29 09:47:45,622 INFO] Writing summaries.\n",
            "2024-03-29 09:47:45,634 [MainThread  ] [INFO ]  Processing summaries. Saving system files to ../temp/tmp0deivrte/system and model files to ../temp/tmp0deivrte/model.\n",
            "[2024-03-29 09:47:45,634 INFO] Processing summaries. Saving system files to ../temp/tmp0deivrte/system and model files to ../temp/tmp0deivrte/model.\n",
            "2024-03-29 09:47:45,634 [MainThread  ] [INFO ]  Processing files in ../temp/rouge-tmp-2024-03-29-09-47-44/candidate/.\n",
            "[2024-03-29 09:47:45,634 INFO] Processing files in ../temp/rouge-tmp-2024-03-29-09-47-44/candidate/.\n",
            "2024-03-29 09:47:46,861 [MainThread  ] [INFO ]  Saved processed files to ../temp/tmp0deivrte/system.\n",
            "[2024-03-29 09:47:46,861 INFO] Saved processed files to ../temp/tmp0deivrte/system.\n",
            "2024-03-29 09:47:46,861 [MainThread  ] [INFO ]  Processing files in ../temp/rouge-tmp-2024-03-29-09-47-44/reference/.\n",
            "[2024-03-29 09:47:46,861 INFO] Processing files in ../temp/rouge-tmp-2024-03-29-09-47-44/reference/.\n",
            "2024-03-29 09:47:47,988 [MainThread  ] [INFO ]  Saved processed files to ../temp/tmp0deivrte/model.\n",
            "[2024-03-29 09:47:47,988 INFO] Saved processed files to ../temp/tmp0deivrte/model.\n",
            "2024-03-29 09:47:48,089 [MainThread  ] [INFO ]  Written ROUGE configuration to ../temp/tmpfn6k_64j/rouge_conf.xml\n",
            "[2024-03-29 09:47:48,089 INFO] Written ROUGE configuration to ../temp/tmpfn6k_64j/rouge_conf.xml\n",
            "2024-03-29 09:47:48,089 [MainThread  ] [INFO ]  Running ROUGE with command /content/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /content/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ../temp/tmpfn6k_64j/rouge_conf.xml\n",
            "[2024-03-29 09:47:48,089 INFO] Running ROUGE with command /content/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /content/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ../temp/tmpfn6k_64j/rouge_conf.xml\n",
            "---------------------------------------------\n",
            "1 ROUGE-1 Average_R: 0.54102 (95%-conf.int. 0.53821 - 0.54369)\n",
            "1 ROUGE-1 Average_P: 0.36869 (95%-conf.int. 0.36632 - 0.37098)\n",
            "1 ROUGE-1 Average_F: 0.42421 (95%-conf.int. 0.42201 - 0.42633)\n",
            "---------------------------------------------\n",
            "1 ROUGE-2 Average_R: 0.24898 (95%-conf.int. 0.24630 - 0.25153)\n",
            "1 ROUGE-2 Average_P: 0.17001 (95%-conf.int. 0.16792 - 0.17200)\n",
            "1 ROUGE-2 Average_F: 0.19516 (95%-conf.int. 0.19294 - 0.19719)\n",
            "---------------------------------------------\n",
            "1 ROUGE-L Average_R: 0.49393 (95%-conf.int. 0.49126 - 0.49658)\n",
            "1 ROUGE-L Average_P: 0.33722 (95%-conf.int. 0.33498 - 0.33955)\n",
            "1 ROUGE-L Average_F: 0.38771 (95%-conf.int. 0.38557 - 0.38977)\n",
            "\n",
            "[2024-03-29 09:49:49,065 INFO] Rouges at step 2000 \n",
            ">> ROUGE-F(1/2/3/l): 42.42/19.52/38.77\n",
            "ROUGE-R(1/2/3/l): 54.10/24.90/49.39\n",
            "\n",
            "[2024-03-29 09:49:49,065 INFO] Validation xent: 5.58129 at step 2000\n",
            "[2024-03-29 09:49:49,119 INFO] Loading checkpoint from ../models/bert_classifier/model_step_1500.pt\n",
            "Namespace(encoder='classifier', mode='validate', bert_data_path='../bert_data/cnndm', model_path='../models/bert_classifier', result_path='../models/bert_classifier/results', temp_dir='../temp', bert_config_path='../bert_config_uncased_base.json', batch_size=10000, use_interval=True, hidden_size=128, ff_size=512, heads=4, inter_layers=2, rnn_size=512, param_init=0, param_init_glorot=True, dropout=0.1, optim='adam', lr=1, beta1=0.9, beta2=0.999, decay_method='', warmup_steps=8000, max_grad_norm=0, save_checkpoint_steps=5, accum_count=1, world_size=1, report_every=1, train_steps=1000, recall_eval=False, visible_gpus='0', gpu_ranks=[0], log_file='../models/bert_classifier/log', dataset='', seed=666, test_all=True, test_from='', train_from='', report_rouge=True, block_trigram=True)\n",
            "[2024-03-29 09:49:56,922 INFO] Loading test dataset from ../bert_data/cnndm.test.0.bert.pt, number of examples: 2001\n",
            "gpu_rank 0\n",
            "[2024-03-29 09:49:56,925 INFO] * number of parameters: 109483009\n",
            "[2024-03-29 09:51:06,185 INFO] Loading test dataset from ../bert_data/cnndm.test.1.bert.pt, number of examples: 2001\n",
            "[2024-03-29 09:52:17,247 INFO] Loading test dataset from ../bert_data/cnndm.test.2.bert.pt, number of examples: 2001\n",
            "[2024-03-29 09:53:30,305 INFO] Loading test dataset from ../bert_data/cnndm.test.3.bert.pt, number of examples: 2001\n",
            "[2024-03-29 09:54:43,555 INFO] Loading test dataset from ../bert_data/cnndm.test.4.bert.pt, number of examples: 2000\n",
            "[2024-03-29 09:55:56,925 INFO] Loading test dataset from ../bert_data/cnndm.test.5.bert.pt, number of examples: 1485\n",
            "11489\n",
            "11489\n",
            "2024-03-29 09:56:52,822 [MainThread  ] [INFO ]  Writing summaries.\n",
            "[2024-03-29 09:56:52,822 INFO] Writing summaries.\n",
            "2024-03-29 09:56:52,824 [MainThread  ] [INFO ]  Processing summaries. Saving system files to ../temp/tmp57_si52f/system and model files to ../temp/tmp57_si52f/model.\n",
            "[2024-03-29 09:56:52,824 INFO] Processing summaries. Saving system files to ../temp/tmp57_si52f/system and model files to ../temp/tmp57_si52f/model.\n",
            "2024-03-29 09:56:52,825 [MainThread  ] [INFO ]  Processing files in ../temp/rouge-tmp-2024-03-29-09-56-51/candidate/.\n",
            "[2024-03-29 09:56:52,825 INFO] Processing files in ../temp/rouge-tmp-2024-03-29-09-56-51/candidate/.\n",
            "2024-03-29 09:56:54,577 [MainThread  ] [INFO ]  Saved processed files to ../temp/tmp57_si52f/system.\n",
            "[2024-03-29 09:56:54,577 INFO] Saved processed files to ../temp/tmp57_si52f/system.\n",
            "2024-03-29 09:56:54,578 [MainThread  ] [INFO ]  Processing files in ../temp/rouge-tmp-2024-03-29-09-56-51/reference/.\n",
            "[2024-03-29 09:56:54,578 INFO] Processing files in ../temp/rouge-tmp-2024-03-29-09-56-51/reference/.\n",
            "2024-03-29 09:56:55,957 [MainThread  ] [INFO ]  Saved processed files to ../temp/tmp57_si52f/model.\n",
            "[2024-03-29 09:56:55,957 INFO] Saved processed files to ../temp/tmp57_si52f/model.\n",
            "2024-03-29 09:56:56,046 [MainThread  ] [INFO ]  Written ROUGE configuration to ../temp/tmpgsckgn7a/rouge_conf.xml\n",
            "[2024-03-29 09:56:56,046 INFO] Written ROUGE configuration to ../temp/tmpgsckgn7a/rouge_conf.xml\n",
            "2024-03-29 09:56:56,046 [MainThread  ] [INFO ]  Running ROUGE with command /content/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /content/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ../temp/tmpgsckgn7a/rouge_conf.xml\n",
            "[2024-03-29 09:56:56,046 INFO] Running ROUGE with command /content/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /content/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ../temp/tmpgsckgn7a/rouge_conf.xml\n",
            "---------------------------------------------\n",
            "1 ROUGE-1 Average_R: 0.53237 (95%-conf.int. 0.52950 - 0.53486)\n",
            "1 ROUGE-1 Average_P: 0.37134 (95%-conf.int. 0.36901 - 0.37368)\n",
            "1 ROUGE-1 Average_F: 0.42310 (95%-conf.int. 0.42097 - 0.42524)\n",
            "---------------------------------------------\n",
            "1 ROUGE-2 Average_R: 0.24317 (95%-conf.int. 0.24028 - 0.24573)\n",
            "1 ROUGE-2 Average_P: 0.16998 (95%-conf.int. 0.16784 - 0.17203)\n",
            "1 ROUGE-2 Average_F: 0.19323 (95%-conf.int. 0.19104 - 0.19532)\n",
            "---------------------------------------------\n",
            "1 ROUGE-L Average_R: 0.48602 (95%-conf.int. 0.48318 - 0.48849)\n",
            "1 ROUGE-L Average_P: 0.33960 (95%-conf.int. 0.33739 - 0.34197)\n",
            "1 ROUGE-L Average_F: 0.38665 (95%-conf.int. 0.38449 - 0.38873)\n",
            "\n",
            "[2024-03-29 09:58:56,731 INFO] Rouges at step 1500 \n",
            ">> ROUGE-F(1/2/3/l): 42.31/19.32/38.66\n",
            "ROUGE-R(1/2/3/l): 53.24/24.32/48.60\n",
            "\n",
            "[2024-03-29 09:58:56,731 INFO] Validation xent: 5.62916 at step 1500\n",
            "[2024-03-29 09:58:56,760 INFO] Loading checkpoint from ../models/bert_classifier/model_step_1000.pt\n",
            "Namespace(encoder='classifier', mode='validate', bert_data_path='../bert_data/cnndm', model_path='../models/bert_classifier', result_path='../models/bert_classifier/results', temp_dir='../temp', bert_config_path='../bert_config_uncased_base.json', batch_size=10000, use_interval=True, hidden_size=128, ff_size=512, heads=4, inter_layers=2, rnn_size=512, param_init=0, param_init_glorot=True, dropout=0.1, optim='adam', lr=1, beta1=0.9, beta2=0.999, decay_method='', warmup_steps=8000, max_grad_norm=0, save_checkpoint_steps=5, accum_count=1, world_size=1, report_every=1, train_steps=1000, recall_eval=False, visible_gpus='0', gpu_ranks=[0], log_file='../models/bert_classifier/log', dataset='', seed=666, test_all=True, test_from='', train_from='', report_rouge=True, block_trigram=True)\n",
            "[2024-03-29 09:59:05,043 INFO] Loading test dataset from ../bert_data/cnndm.test.0.bert.pt, number of examples: 2001\n",
            "gpu_rank 0\n",
            "[2024-03-29 09:59:05,046 INFO] * number of parameters: 109483009\n",
            "[2024-03-29 10:00:14,132 INFO] Loading test dataset from ../bert_data/cnndm.test.1.bert.pt, number of examples: 2001\n",
            "[2024-03-29 10:01:25,870 INFO] Loading test dataset from ../bert_data/cnndm.test.2.bert.pt, number of examples: 2001\n",
            "[2024-03-29 10:02:38,268 INFO] Loading test dataset from ../bert_data/cnndm.test.3.bert.pt, number of examples: 2001\n",
            "[2024-03-29 10:03:51,462 INFO] Loading test dataset from ../bert_data/cnndm.test.4.bert.pt, number of examples: 2000\n",
            "[2024-03-29 10:05:05,000 INFO] Loading test dataset from ../bert_data/cnndm.test.5.bert.pt, number of examples: 1485\n",
            "11489\n",
            "11489\n",
            "2024-03-29 10:06:00,819 [MainThread  ] [INFO ]  Writing summaries.\n",
            "[2024-03-29 10:06:00,819 INFO] Writing summaries.\n",
            "2024-03-29 10:06:00,821 [MainThread  ] [INFO ]  Processing summaries. Saving system files to ../temp/tmp90na97p_/system and model files to ../temp/tmp90na97p_/model.\n",
            "[2024-03-29 10:06:00,821 INFO] Processing summaries. Saving system files to ../temp/tmp90na97p_/system and model files to ../temp/tmp90na97p_/model.\n",
            "2024-03-29 10:06:00,821 [MainThread  ] [INFO ]  Processing files in ../temp/rouge-tmp-2024-03-29-10-05-59/candidate/.\n",
            "[2024-03-29 10:06:00,821 INFO] Processing files in ../temp/rouge-tmp-2024-03-29-10-05-59/candidate/.\n",
            "2024-03-29 10:06:02,677 [MainThread  ] [INFO ]  Saved processed files to ../temp/tmp90na97p_/system.\n",
            "[2024-03-29 10:06:02,677 INFO] Saved processed files to ../temp/tmp90na97p_/system.\n",
            "2024-03-29 10:06:02,682 [MainThread  ] [INFO ]  Processing files in ../temp/rouge-tmp-2024-03-29-10-05-59/reference/.\n",
            "[2024-03-29 10:06:02,682 INFO] Processing files in ../temp/rouge-tmp-2024-03-29-10-05-59/reference/.\n",
            "2024-03-29 10:06:03,940 [MainThread  ] [INFO ]  Saved processed files to ../temp/tmp90na97p_/model.\n",
            "[2024-03-29 10:06:03,940 INFO] Saved processed files to ../temp/tmp90na97p_/model.\n",
            "2024-03-29 10:06:04,021 [MainThread  ] [INFO ]  Written ROUGE configuration to ../temp/tmp0iqfz4u8/rouge_conf.xml\n",
            "[2024-03-29 10:06:04,021 INFO] Written ROUGE configuration to ../temp/tmp0iqfz4u8/rouge_conf.xml\n",
            "2024-03-29 10:06:04,022 [MainThread  ] [INFO ]  Running ROUGE with command /content/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /content/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ../temp/tmp0iqfz4u8/rouge_conf.xml\n",
            "[2024-03-29 10:06:04,022 INFO] Running ROUGE with command /content/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /content/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ../temp/tmp0iqfz4u8/rouge_conf.xml\n",
            "---------------------------------------------\n",
            "1 ROUGE-1 Average_R: 0.53681 (95%-conf.int. 0.53392 - 0.53939)\n",
            "1 ROUGE-1 Average_P: 0.36349 (95%-conf.int. 0.36110 - 0.36574)\n",
            "1 ROUGE-1 Average_F: 0.41934 (95%-conf.int. 0.41713 - 0.42146)\n",
            "---------------------------------------------\n",
            "1 ROUGE-2 Average_R: 0.24387 (95%-conf.int. 0.24101 - 0.24646)\n",
            "1 ROUGE-2 Average_P: 0.16555 (95%-conf.int. 0.16337 - 0.16748)\n",
            "1 ROUGE-2 Average_F: 0.19050 (95%-conf.int. 0.18818 - 0.19258)\n",
            "---------------------------------------------\n",
            "1 ROUGE-L Average_R: 0.48958 (95%-conf.int. 0.48676 - 0.49211)\n",
            "1 ROUGE-L Average_P: 0.33206 (95%-conf.int. 0.32975 - 0.33420)\n",
            "1 ROUGE-L Average_F: 0.38281 (95%-conf.int. 0.38062 - 0.38483)\n",
            "\n",
            "[2024-03-29 10:08:10,750 INFO] Rouges at step 1000 \n",
            ">> ROUGE-F(1/2/3/l): 41.93/19.05/38.28\n",
            "ROUGE-R(1/2/3/l): 53.68/24.39/48.96\n",
            "\n",
            "[2024-03-29 10:08:10,751 INFO] Validation xent: 5.77612 at step 1000\n"
          ]
        }
      ],
      "source": [
        "!python train.py -mode validate \\\n",
        "          -bert_data_path ../bert_data/cnndm \\\n",
        "          -model_path ../models/bert_classifier  \\\n",
        "          -visible_gpus 0  -gpu_ranks 0 \\\n",
        "          -batch_size 10000  \\\n",
        "          -log_file ../models/bert_classifier/log  \\\n",
        "          -result_path ../models/bert_classifier/results \\\n",
        "          -test_all -block_trigram true"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}